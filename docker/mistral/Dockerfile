# Mistral LLM via Ollama
# ======================
# Docker container for Mistral model using Ollama

FROM ollama/ollama:latest

# Expose Ollama API port
EXPOSE 11434

# Note: The mistral model will be pulled on first container start
# You can pre-pull by running: docker exec <container> ollama pull mistral

# The ollama/ollama image handles the entrypoint automatically
